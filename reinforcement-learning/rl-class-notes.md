## Coursera  Specialization #1 - Reinforcement Learning

### Course #1 - Fundamentals of Reinforcement Learning

------------

#### Module 1 Outline 

* **Lesson 1: The K-Armed Bandit Problem**

  - Define reward

  - Understand the temporal nature of the bandit problem

  - Define k-armed bandit

  - Define action-values

* **Lesson 2: What to Learn? Estimating Action Values**

  - Define action-value estimation methods

  - Define exploration and exploitation

  - Select actions greedily using an action-value function

  - Define online learning

  - Understand a simple online sample-average action-value estimation method

  - Define the general online update equation

  - Understand why we might use a constant step-size in the case of non-stationarity 

* **Lesson 3: Exploration vs. Exploitation Tradeoff** 

  - Define epsilon-greedy

  - Compare the short-term benefits of exploitation and the long-term benefits of exploration

  - Understand optimistic initial values

  - Describe the benefits of optimistic initial values for early exploration

  - Explain the criticisms of optimistic initial values

  - Describe the upper confidence bound action selection method

  - Define optimism in the face of uncertainty  

  
